{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.foxnews.com/category/shows/tucker-carlson-tonight/transcript\")\n",
    "button = driver.find_element(By.XPATH, \"//div[@class='button load-more js-load-more']\") \n",
    "x = 0\n",
    "for x in range(144):\n",
    "    button.click()    \n",
    "    time.sleep(2)\n",
    "    x+=1\n",
    "    print(x)\n",
    "page_source = driver.page_source # save the source to feed to beautiful soup \n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_soup = soup.find_all('a', href=re.compile('/opinion/.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "prefix = 'https://www.foxnews.com/'\n",
    "for link in url_soup: \n",
    "    suffix = re.findall('\\\"\\/(.*?)\\\"', str(link))\n",
    "    if suffix:\n",
    "        url_list.append(prefix + suffix[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list  = [*set(url_list)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # verifying for one instance\n",
    "# url = url_list[100]\n",
    "# #url = 'https://www.foxnews.com/opinion/tucker-carlson-faa-travel-pete-buttigieg'\n",
    "# response = requests.get(url)\n",
    "# soup = BeautifulSoup(response.content)\n",
    "# title = soup.title.string\n",
    "\n",
    "# a_tag = soup.find_all('a')\n",
    "# for tag in a_tag:\n",
    "#     tag.decompose()\n",
    "\n",
    "# copy_tag = soup.find_all('p', class_ = \"copyright\")\n",
    "# for tag in copy_tag:\n",
    "#     tag.decompose()\n",
    "    \n",
    "# span_tag = soup.find_all('span')\n",
    "# for tag in span_tag:\n",
    "#     tag.decompose()\n",
    "    \n",
    "# bold_tag = soup.find_all('strong') \n",
    "# for tag in bold_tag:\n",
    "#     tag.decompose()\n",
    "    \n",
    "# italic_tag=soup.find_all('i') \n",
    "# for tag in italic_tag:\n",
    "#     tag.decompose()\n",
    "\n",
    "# other_tag = soup.find_all('p', class_ =\"dek\")\n",
    "# for tag in other_tag:\n",
    "#     tag.decompose()\n",
    "    \n",
    "# other_tag2 = soup.find_all('p', class_ =\"subscribed hide\")\n",
    "# for tag in other_tag2:\n",
    "#     tag.decompose()\n",
    "    \n",
    "# other_tag3 = soup.find_all('p', class_ =\"success hide\") \n",
    "# for tag in other_tag3:\n",
    "#     tag.decompose()\n",
    "\n",
    "\n",
    "\n",
    "# final = soup.find_all('p')\n",
    "\n",
    "# finaltext = \"\"\n",
    "# for p in final:\n",
    "\n",
    "#     try:\n",
    "#         if len(p.text) > 1:\n",
    "#             finaltext = finaltext + p.text + '\\n'+ '\\n'\n",
    "#             finaltext = finaltext.replace('\\xa0', ' ')\n",
    "\n",
    "#     except:\n",
    "#         continue\n",
    "# print(finaltext)\n",
    "len(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_df = None\n",
    "dfs = []\n",
    "\n",
    "for n, url in enumerate(url_list):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    time = soup.find('time').text\n",
    "    title = soup.title.string\n",
    "\n",
    "    a_tag = soup.find_all('a')\n",
    "    for tag in a_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    copy_tag = soup.find_all('p', class_ = \"copyright\")\n",
    "    for tag in copy_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    span_tag = soup.find_all('span')\n",
    "    for tag in span_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    bold_tag = soup.find_all('strong') \n",
    "    for tag in bold_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    italic_tag=soup.find_all('i') \n",
    "    for tag in italic_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    other_tag = soup.find_all('p', class_ =\"dek\")\n",
    "    for tag in other_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    other_tag2 = soup.find_all('p', class_ =\"subscribed hide\")\n",
    "    for tag in other_tag2:\n",
    "        tag.decompose()\n",
    "\n",
    "    other_tag3 = soup.find_all('p', class_ =\"success hide\") \n",
    "    for tag in other_tag3:\n",
    "        tag.decompose()\n",
    "\n",
    "\n",
    "    final = soup.find_all('p')\n",
    "    # text=''\n",
    "    # print(final)\n",
    "    finaltext = ''\n",
    "    for p in final:\n",
    "        try:\n",
    "            if len(p.text) > 1:\n",
    "                finaltext = finaltext + p.text + '\\n'+ '\\n'\n",
    "                finaltext = finaltext.replace('\\xa0', ' ')\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    data={'url': [url],'timestamp': [time], 'title': [title], 'transcript': [finaltext]}\n",
    "    df = pd.DataFrame(data)\n",
    "    dfs.append(df)\n",
    "\n",
    "full_df = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "full_df['timestamp'] = pd.to_datetime(full_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df=full_df.sort_values(by=['timestamp']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('data/Tucker_transcripts.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2018-11-27 08:39:00</td>\n",
       "      <td>Tucker Carlson: Socialism with open borders is...</td>\n",
       "      <td>Democrats want to eliminate restrictions on im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2018-11-28 07:16:00</td>\n",
       "      <td>Tucker Carlson: For the crime of forgetting, J...</td>\n",
       "      <td>Jerome Corsi addresses charges against him in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2018-11-29 11:12:00</td>\n",
       "      <td>Tucker Carlson: The word 'Russia' eliminates a...</td>\n",
       "      <td>On Wednesday, Tucker Carlson exposes the flaws...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2018-11-30 09:21:00</td>\n",
       "      <td>Tucker Carlson: The Mueller probe and what we ...</td>\n",
       "      <td>Michael Cohen pleads guilty to lying to Congre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2018-12-04 08:08:00</td>\n",
       "      <td>Tucker Carlson: The Mueller probe continues to...</td>\n",
       "      <td>On Monday, Tucker Carlson talks to Jerome Cors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2023-03-10 22:41:00</td>\n",
       "      <td>TUCKER CARLSON: Silicon Valley Bank has gone c...</td>\n",
       "      <td>Fox News host Tucker Carlson breaks down the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2023-03-13 23:06:00</td>\n",
       "      <td>TUCKER CARLSON: The Biden administration sees ...</td>\n",
       "      <td>Fox News host Tucker Carlson takes a closer lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2023-03-14 23:57:00</td>\n",
       "      <td>TUCKER CARLSON: We're getting moral lectures f...</td>\n",
       "      <td>Fox News host Tucker Carlson calls out wokenes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2023-03-15 23:22:00</td>\n",
       "      <td>TUCKER CARLSON: You're going to get a hot war ...</td>\n",
       "      <td>Fox News host Tucker Carlson calls out the Bid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>https://www.foxnews.com/opinion/tucker-carlson...</td>\n",
       "      <td>2023-03-16 22:41:00</td>\n",
       "      <td>TUCKER CARLSON: Climate change experts' bullyi...</td>\n",
       "      <td>Fox News host Tucker Carlson calls out climate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url           timestamp  \\\n",
       "0    https://www.foxnews.com/opinion/tucker-carlson... 2018-11-27 08:39:00   \n",
       "1    https://www.foxnews.com/opinion/tucker-carlson... 2018-11-28 07:16:00   \n",
       "2    https://www.foxnews.com/opinion/tucker-carlson... 2018-11-29 11:12:00   \n",
       "3    https://www.foxnews.com/opinion/tucker-carlson... 2018-11-30 09:21:00   \n",
       "4    https://www.foxnews.com/opinion/tucker-carlson... 2018-12-04 08:08:00   \n",
       "..                                                 ...                 ...   \n",
       "826  https://www.foxnews.com/opinion/tucker-carlson... 2023-03-10 22:41:00   \n",
       "827  https://www.foxnews.com/opinion/tucker-carlson... 2023-03-13 23:06:00   \n",
       "828  https://www.foxnews.com/opinion/tucker-carlson... 2023-03-14 23:57:00   \n",
       "829  https://www.foxnews.com/opinion/tucker-carlson... 2023-03-15 23:22:00   \n",
       "830  https://www.foxnews.com/opinion/tucker-carlson... 2023-03-16 22:41:00   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Tucker Carlson: Socialism with open borders is...   \n",
       "1    Tucker Carlson: For the crime of forgetting, J...   \n",
       "2    Tucker Carlson: The word 'Russia' eliminates a...   \n",
       "3    Tucker Carlson: The Mueller probe and what we ...   \n",
       "4    Tucker Carlson: The Mueller probe continues to...   \n",
       "..                                                 ...   \n",
       "826  TUCKER CARLSON: Silicon Valley Bank has gone c...   \n",
       "827  TUCKER CARLSON: The Biden administration sees ...   \n",
       "828  TUCKER CARLSON: We're getting moral lectures f...   \n",
       "829  TUCKER CARLSON: You're going to get a hot war ...   \n",
       "830  TUCKER CARLSON: Climate change experts' bullyi...   \n",
       "\n",
       "                                            transcript  \n",
       "0    Democrats want to eliminate restrictions on im...  \n",
       "1    Jerome Corsi addresses charges against him in ...  \n",
       "2    On Wednesday, Tucker Carlson exposes the flaws...  \n",
       "3    Michael Cohen pleads guilty to lying to Congre...  \n",
       "4    On Monday, Tucker Carlson talks to Jerome Cors...  \n",
       "..                                                 ...  \n",
       "826  Fox News host Tucker Carlson breaks down the c...  \n",
       "827  Fox News host Tucker Carlson takes a closer lo...  \n",
       "828  Fox News host Tucker Carlson calls out wokenes...  \n",
       "829  Fox News host Tucker Carlson calls out the Bid...  \n",
       "830  Fox News host Tucker Carlson calls out climate...  \n",
       "\n",
       "[831 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
